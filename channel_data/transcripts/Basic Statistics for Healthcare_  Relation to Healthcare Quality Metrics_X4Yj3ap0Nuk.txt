Title: Basic Statistics for Healthcare:  Relation to Healthcare Quality Metrics
URL: https://www.youtube.com/watch?v=X4Yj3ap0Nuk
Author: AHealthcareZ - Healthcare Finance Explained
Language: en

Transcription:
 Hello, this is Dr. Eric Bricker and thank you for watching A Healthcare Z. Today we're going to be discussing basics in healthcare statistics. Now yesterday we talked about history, today we're talking about statistics. I mean I am boring you folks to tears, but you are sticking with me. So thank you so much for that. So for today I promise to make it very short and very practical. Okay, but we're dealing with data a lot in healthcare and so we have to have a basic understanding of statistics. So when data analysis is performed, sort of the basic level of understanding that we all need to have is something that's called hypothesis testing. And it's typically used in like, let's say a drug trial, but it's used essentially all over the place when you're dealing with statistical analysis. But let's just use a drug trial example where you have drug X, let's say, does it lower blood pressure versus placebo? Now you have two hypotheses. You have what's called the null hypothesis, which is abbreviated H0 or H with a little sub zero, which is the null hypothesis, which means there is no difference between the tested blood pressure drug and placebo, sugar pill, etc. Okay, and then there's the alternative hypothesis, which is abbreviated H sub A. And that is, is that they're different. Okay, so what you're doing with hypothesis testing is you're looking at their data and you're saying, hey, is there a difference? And that's important because notice that you have to form a specific question or a hypothesis that you're testing when you're looking at the data. Okay, well, there's different ways to generate data. And we're only going to do two of those ways today. And related to the drug trial, we have what are referred to as randomized controlled trials. So this is sort of the gold standard. This is what the FDA uses, where one, it's randomized. So in this situation here, if you have a group of 100 people, then you're going to, you know, flip a coin and say, heads, you get the blood pressure medication, tails, you get the placebo. Okay, so it's randomized. And then it's controlled in that all the other situations around the person's blood pressure are controlled as much as possible. And the reason for that is because you're testing specifically this intervention to see if this specific thing here is what's causing the change in the blood pressure, as opposed to something else. Okay, and that has to be done on a prospective basis. And not only do they do that, but they also oftentimes double blind it, meaning that they're going to be able to do that. And that the patient or the test subject themselves doesn't know whether they're taking the blood pressure pill or they're taking the placebo. Because let's say you take the placebo, and you know you're taking the placebo, and you're all stressed out that you're taking the placebo, because you're like, oh, it's not going to work. It's only a sugar pill. And so that raises your blood pressure. And so you might say, oh, well, look, the blood pressure pill works versus the placebo, because the people taking the placebo were stressed out. Okay, so that's why it has to be blinded. And then it even has to be blinded to the researchers themselves. When they're analyzing the data, they can't know which group had the placebo versus the blood pressure pill, because the researchers themselves will subconsciously or consciously bias their analysis of the data to give them the results they want. Okay, fine. What's another way to generate data? So this is an observational study, right? And so this is where, you know, we might observe a surgical complication rate at one hospital versus another, or for one surgeon versus another. Again, you can have a null hypothesis, which says there's no difference between x and y, no difference between one hospital or another, no difference between one surgeon or another, no difference between one state or metro area and another. And then there's the alternative hypothesis, that there is a difference. Because it is not randomized, right? You don't randomize the people that went to one hospital or another, or that went to one surgeon or another, because it's life. It just kind of happened on its own. Okay, so because we cannot prospectively randomize it, what that means is, and this is the point I'm making with this video, is that an observational study only proves correlation, not causation. It's the whole rooster crowing and the sun rising thing, right? The two of them happen together, but it doesn't mean that the rooster crowing caused the sun to rise. Okay? Now, why is this specifically practical to healthcare finance? It's because in the news, it's constantly talked about healthcare quality, quality this, quality that, blah, blah, blah, right? So quality metrics are typically measured through observational studies. It is not a risk-adjusted study. They typically do not randomize patients between two hospitals. They don't randomize patients between two surgeons. So in fact, and this is the classic case, is to say, okay, well, maybe a particular surgeon or doctor has a worse outcome because we're measuring something else. And what they do is they try to do risk adjustment to try to adjust for that something else. Oh, my patients are sicker, therefore I have a higher complication rate. Okay? Risk adjustment is not a perfect solution for turning an observational study into a randomized controlled trial and then proving causation. So just, I mean, it's like, I'll give you a specific example. I am an attending physician at Johns Hopkins, who is one of the world's foremost experts on aplastic anemia, which is when your bone marrow essentially quits making red blood cells. And that leads to death. Like, you cannot live without red blood cells, right? And so there are various things you can do to try to treat that, but in general, the outcome is really bad. And so maybe this doctor and Johns Hopkins' outcomes for aplastic anemia are, like, worse than the national average. Like, does that, you know, are, can't, how, do you, and because they don't fully understand aplastic anemia, it's really hard to risk adjust for, like, are his patients sicker or not as sick? Because they don't really fully understand how the disease even works. Okay? So the point is, is anytime you look at quality data or quality data is presented to you or you look at a difference in terms of quality, you need to be very careful. And in your mind, tell yourself, look, this only says correlation. It does not say causation. And that's my point for today. Thank you for watching A Healthcare Z.

Detailed segments with timestamps:

[0:00 - 0:28]  Hello, this is Dr. Eric Bricker and thank you for watching A Healthcare Z. Today we're going to be discussing basics in healthcare statistics. Now yesterday we talked about history, today we're talking about statistics. I mean I am boring you folks to tears, but you are sticking with me. So thank you so much for that. So for today I promise to make it very short and very practical. Okay, but we're dealing with data a lot in healthcare and so we have to have a basic understanding of statistics.
[0:28 - 0:51]  So when data analysis is performed, sort of the basic level of understanding that we all need to have is something that's called hypothesis testing. And it's typically used in like, let's say a drug trial, but it's used essentially all over the place when you're dealing with statistical analysis. But let's just use a drug trial example where you have drug X, let's say, does it lower blood pressure versus placebo?
[0:51 - 1:08]  Now you have two hypotheses. You have what's called the null hypothesis, which is abbreviated H0 or H with a little sub zero, which is the null hypothesis, which means there is no difference between the tested blood pressure drug and placebo, sugar pill, etc.
[1:08 - 1:21]  Okay, and then there's the alternative hypothesis, which is abbreviated H sub A. And that is, is that they're different. Okay, so what you're doing with hypothesis testing is you're looking at their data and you're saying, hey, is there a difference?
[1:21 - 1:35]  And that's important because notice that you have to form a specific question or a hypothesis that you're testing when you're looking at the data. Okay, well, there's different ways to generate data. And we're only going to do two of those ways today.
[1:35 - 2:01]  And related to the drug trial, we have what are referred to as randomized controlled trials. So this is sort of the gold standard. This is what the FDA uses, where one, it's randomized. So in this situation here, if you have a group of 100 people, then you're going to, you know, flip a coin and say, heads, you get the blood pressure medication, tails, you get the placebo. Okay, so it's randomized.
[2:01 - 2:31]  And then it's controlled in that all the other situations around the person's blood pressure are controlled as much as possible. And the reason for that is because you're testing specifically this intervention to see if this specific thing here is what's causing the change in the blood pressure, as opposed to something else. Okay, and that has to be done on a prospective basis. And not only do they do that, but they also oftentimes double blind it, meaning that they're going to be able to do that.
[2:31 - 2:47]  And that the patient or the test subject themselves doesn't know whether they're taking the blood pressure pill or they're taking the placebo. Because let's say you take the placebo, and you know you're taking the placebo, and you're all stressed out that you're taking the placebo, because you're like, oh, it's not going to work. It's only a sugar pill.
[2:47 - 3:17]  And so that raises your blood pressure. And so you might say, oh, well, look, the blood pressure pill works versus the placebo, because the people taking the placebo were stressed out. Okay, so that's why it has to be blinded. And then it even has to be blinded to the researchers themselves. When they're analyzing the data, they can't know which group had the placebo versus the blood pressure pill, because the researchers themselves will subconsciously or consciously bias their analysis of the data to give them the results they want. Okay, fine. What's another way to generate data?
[3:17 - 3:47]  So this is an observational study, right? And so this is where, you know, we might observe a surgical complication rate at one hospital versus another, or for one surgeon versus another. Again, you can have a null hypothesis, which says there's no difference between x and y, no difference between one hospital or another, no difference between one surgeon or another, no difference between one state or metro area and another. And then there's the alternative hypothesis, that there is a difference.
[3:47 - 4:15]  Because it is not randomized, right? You don't randomize the people that went to one hospital or another, or that went to one surgeon or another, because it's life. It just kind of happened on its own. Okay, so because we cannot prospectively randomize it, what that means is, and this is the point I'm making with this video, is that an observational study only proves correlation, not causation. It's the whole rooster crowing and the sun rising thing, right?
[4:15 - 4:42]  The two of them happen together, but it doesn't mean that the rooster crowing caused the sun to rise. Okay? Now, why is this specifically practical to healthcare finance? It's because in the news, it's constantly talked about healthcare quality, quality this, quality that, blah, blah, blah, right? So quality metrics are typically measured through observational studies. It is not a risk-adjusted study.
[4:42 - 4:57]  They typically do not randomize patients between two hospitals. They don't randomize patients between two surgeons. So in fact, and this is the classic case, is to say, okay, well, maybe a particular surgeon or doctor has a worse outcome because we're measuring something else.
[4:58 - 5:08]  And what they do is they try to do risk adjustment to try to adjust for that something else. Oh, my patients are sicker, therefore I have a higher complication rate. Okay?
[5:08 - 5:23]  Risk adjustment is not a perfect solution for turning an observational study into a randomized controlled trial and then proving causation. So just, I mean, it's like, I'll give you a specific example.
[5:23 - 5:32]  I am an attending physician at Johns Hopkins, who is one of the world's foremost experts on aplastic anemia, which is when your bone marrow essentially quits making red blood cells.
[5:32 - 5:37]  And that leads to death. Like, you cannot live without red blood cells, right?
[5:37 - 5:43]  And so there are various things you can do to try to treat that, but in general, the outcome is really bad.
[5:44 - 5:50]  And so maybe this doctor and Johns Hopkins' outcomes for aplastic anemia are, like, worse than the national average.
[5:50 - 6:01]  Like, does that, you know, are, can't, how, do you, and because they don't fully understand aplastic anemia, it's really hard to risk adjust for, like, are his patients sicker or not as sick?
[6:01 - 6:05]  Because they don't really fully understand how the disease even works.
[6:05 - 6:05]  Okay?
[6:06 - 6:13]  So the point is, is anytime you look at quality data or quality data is presented to you or you look at a difference in terms of quality, you need to be very careful.
[6:13 - 6:17]  And in your mind, tell yourself, look, this only says correlation.
[6:18 - 6:19]  It does not say causation.
[6:20 - 6:21]  And that's my point for today.
[6:21 - 6:23]  Thank you for watching A Healthcare Z.